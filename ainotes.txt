uninformed search 

complete- search that finds a solution (if one exists) 
optimal- finds the best solution 

state- problem state (e.g. "Arad")
node-has a state, a parent, possibly children, possibly cost (e.g. "Arad", "Sibiu", 220)

branching factor- number of child nodes per parent node

depth- distance from root to deepest node 


big O and trees 

given a branching factor of b and a depth m, how many nodes are in the tree? 

depth 0, 1 node 
depth 1, b nodes 
depth 2, b^2 nodes
depth 3, b^3 nodes 
....
depth m, b^m 

Total number of nodes 
1 + b + b^2 + b^3 + ... + b^m = (1-b^(m+1))/(1-b) 
O(b^m)

tree search 
frontier = {root}
while no solution and frontier is not empty
	curNode = frontier.getNode()
	check if it's the solution 
	add children of curNode to frontier 
	

graph search (don't repeat states) 
Collection<Node> frontier = {root}
Collection<State> visited = {root}
while no solution and frontier is not empty
	curNode = frontier.getNode()
	
	check if it's the solution 
	for child in children of curNode 
		
		if child is not in visited 
			frontier.add(child) 
		visited.add(child)
	
What data structure is frontier?
stack- depth first search 
complete? depends if its graph (yes) or tree (no, could get in an infinite loop)
Arad, Sibiu, Arad, Sibiu, Arad, Sibiu, ...
optimal? 
no 
space? 
O(bm) 
speed? 
O(b^m) 

queue- breadth first search 
complete?
yes 
optimal? 
yes 
space? 
O(b^(m-1))
speed?
O(b^m) 

depth limited search- depth first search, but stop if you hit a particular depth d 
complete? 
yes if d>=m, no generally 
optimal? 
no 
space?
O(bd)
speed?
O(b^d) 

iterative deepening 
do a depth limited search.  If it fails, increase depth by 1.
DLS(1), then DLS(2), then DLS(3), ... , DLS(m)
complete? 
yes 
optimal? 
yes 
space?
O(m) 
speed? 
O(b^m)

DLS(0) takes 1
DLS(1) takes b
DLS(2) takes b^2 
DLS(3) takes b^3
....
DLS(m) takes b^m 
1+b+b^2+b^3+...+b^m=O(b^m)


priority queue (ordered by current cost)- uniform cost 
(same issues as bfs) 

	
puzzle 
https://www.chiark.greenend.org.uk/~sgtatham/puzzles/js/fifteen.html


frontier = {initial node}
explored = {}
while frontier isn't empty:
	choose a node N from the frontier, return N if it's a solution
		bfs, queue
		dfs, stack
		uniform cost, priority queue ranked on current distance 
	expand N
		add new nodes to the frontier 
			(don't add nodes already explored)
		depth limited: don't expand if past depth 
	
	
if frontier is empty, return fail


arad to bucharest 

bfs 
arad 

sibiu (arad)
timisoara (arad)
zerind (arad)

fagaras (sibiu)
oradea (sibiu)
rimnicu vilcea (sibiu)
lugoj (timosoara) 

bucharest (fagaras)
pitesti (rimnicu vilcea)
craiova (rimnicu vilcea)
mehadia (lugoj)

expand bucharest (found solution) 
found the shortest path in nodes, not in distance 

dfs 

cur node			stack 
					arad 
arad				zerind, timisoara, sibiu
zerind (arad)		oradea, timisoara, sibiu
oradea	(arad)		timisoara, sibiu
timisoara (arad)	lugoj, sibiu 
lugoj (timi)		mehadia, sibiu 
mehadia	(lugoj)		dobreta, sibiu 
dobreta (mehadia)	craiova, sibiu 
craiova (dobreta)	rimnicu vilcea, pitesti, sibiu
rimnicu vilcea 		pitesti, sibiu
pitesti				bucharest, sibiu 
bucharest			sibiu


we can implement dfs and bfs as special cases of uniform cost 
bfs: cost is number of nodes visited 
dfs: cost is -(number of nodes visited) 


uniform cost 	priority queue
				(arad, 0)
(arad, 0)		(sibiu, 140), (timisoara, 118), (zerind, 75)
(zerind, 75)	(oradea, 71+75=146), (sibiu, 140), (timisoara, 118)
(timisoara, 118) (lugoj, 118+111=229), (oradea, 146), (sibiu, 140)
(sibiu, 140)	(lugoj, 229), (oradea, 146), (rv, 220), (fagaras, 239)
(oradea, 146)	(lugoj, 229), (rv, 220), (fagaras, 239)
(rv, 220)		(lugoj, 229), (pitesti, 317), (craiova, 366),(fagaras, 239)
	
	
current node		priority queue 
					(s, 0)
(s, 0)				(a, 1), (b,2)
(a, 1)				(b,2), (c,4)
(b,2)				(c,3), (c,4)
(c,3)				(c,4), (t,4)
(c,4) ignore		(t,4)
(t,4)
	
Either, you need a way to update nodes in the priority queue, or add a new node with the same state (and deal with extra node when it comes off).	


A* search 
priority queue search 
f - evaluation function
g - cost function 

f = g -> uniform cost 

h - heuristic function (guess at the distance to the goal) 

A*
f = g + h 
	
greedy best first search 
f = h 	

	
	
eights puzzle 
g - total tiles move to this point 

h - number of tiles out of place 
h - how far each tile is from correct spot
	pretend you can move tiles on top of other tiles 
	
	
	
	
	
turing test

thinks a computer needs 10^9 memory/hard drive to imitate a human 

can computer convince a human that it's human? 
text message window, human is allowed to ask questions of the machine (?) and then has to say if it's human or a computer. 


human is talking to A 

"A" might be a human or a computer.  

depends on the tester 

captchas are reverse turing tests.  


1. Theological
Humans are divinely gifted. 

2. Head in the sand
I really hope computers can't do this.

3. Mathematical objection
There are things a computer provably cannot do.

e.g.
Find all bugs in a program.
Tell if a program halts.  

4. Consciousness
Computers can't be conscious.  

5. Disability
Computers aren't able to do X.
Computers are necessarily specialized to a particular task.
Computers don't make mistakes.  

6. Computers can't do anything they are not programmed.

7. Nervous system is continuous, computers are discrete.  

8. Behavior is informal/ not guided by rules.

9. ESP- extra sensory perception 





Games

chess
go/baduk/weiqui ~361!
checkers
tic tac toe
othello
mancala
shogi
xianqi
connect4 
gomoku


two player games
deteriministic (no random elements) 
complete information (no hidden information)
discrete
zero sum (one winner, one loser)



maxPlayer(curState)
	if curState is terminal
		return value
	else
		best = -1000000
		for each childState
			best = max(best, minPlayer(childState) )

		return best

minPlayer(curState)
	if curState is terminal
		return value
	else
		best = 1000000
		for each childState
			best = min(best, maxPlayer(childState) )

		return best
		
findMoveMax(state)
	bestMove = null
	bestVal = -10000
	for each move 
		curVal = minPlayer(childState)
		if(curVal > bestVal)
			bestMove = move
			bestVal = curVal 
	return bestMove 

This solves all games of this type, but the tree is too big for everything but tic tac toe.  

New plan: try to figure out if we are winning without searching the entire tree.  


maxPlayer(curState, depthLeft)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		best = -1000000
		for each childState
			best = max(best, minPlayer(childState, depthLeft-1) )

		return best



What is a static evaluation?
A relatively fast way of assigning a value to a state. 
In chess, a simple one is you count up the pieces each side has.  (A slightly more complex one assigns values to each piece type).  



alpha is what the max player can guarantee
beta is what the min can guarantee 
initially alpha = -infinity, beta = infinity 
maxPlayer(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			
			curValue = minPlayer(childState, depthLeft-1, alpha, beta)
			if(curValue >= beta) // if we can do better than beta, min player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue > alpha // if we can guarantee we do better than previously known, update it 
				alpha = curValue 

		return alpha 


alpha is what the max player can guarantee
beta is what the min can guarantee 
initially alpha = -infinity, beta = infinity 
minPlayer(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			
			curValue = maxPlayer(childState, depthLeft-1, alpha, beta)
			if(curValue <= alpha) // if we can do better than alpha, max player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue < beta // if we can guarantee we do better than previously known, update it 
				beta = curValue 

		return beta 


assuming we are the max player 
negaMax(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			curValue = -negaMax(childState, depthLeft-1, -beta, -alpha)
			if(curValue >= beta) // if we can do better than beta, min player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue > alpha // if we can guarantee we do better than previously known, update it 
				alpha = curValue 
	return alpha 


How much faster is this?
It depends on the order moves are considered.
Minimax is b^d.
If the moves are considered in best to worst order, b^(d/2)
If the moves are considered worst to best, it's b^d. 
If the moves are random, it's b^(3d/4)

If we knew which moves were best, we wouldn't have to do this in the first place.  
One of the places where cleverness comes in is what order to try moves.  Try moves that are usually good first.  It sometimes can be worth it to do a small depth search in order to sort the moves for a large depth search.  






two player games
complete information (no hidden information)
discrete
zero sum (one winner, one loser)

Add in random elements, e.g. card games (without secret hands), dice, dominoes, 



expected value: the average result from a random occurence 

For example, roll one die.

1  1/6
2  1/6
3  1/6 
4  1/6
5  1/6
6  1/6 

Expected value of one die is 1/6 *1 + 1/6 * 2 + 1/6 * 3 + 1/6 * 4 + 1/6 * 5 + 1/6 * 6 = 3.5

Expected value of two dice is 1/36 * 2 + 2/36 * 3 + 3/36 *4 +... + 1/36*12 = 7
11
12
13
14
15
16
21
22
23
24
25
26


What is the expected value of the square of the result of rolling one die?  

1/6 * 1 + 1/6 * 4 + 1/6*9 + 1/6*16 + 1/6 *25 + 1/6*36 = 91/6


2 biased coins.  Chance of heads is .3 on each coin.  You get $3 per heads.  What is the expected payout?

TH  .7*.3  *  3 = .63
HT  .3*.7  *  3 = .63
TT  .7*.7  *  0 = 0
HH  .3*.3  *  6 = .54
.63+.63+.54=1.8 


Solving a stochastic game: (stochastic means nondeterminstic/random)
1. Add chance nodes to our tree (as well as max and min).  
2. At chance nodes, compute the expected value.  



Problems:
1. Often, random events create large branching factors.  
2. If we cut off at a depth, our static evaluation has to not just order states, but give an estimation of winning percentage.  
3. Alpha beta can still work, but it's more complicated.  


a .9 4, .1 5   = 4.1
b .8 2, .2 20  = 5.6
c .8 2, .2 6   = 2.8 


Solution (?):  Instead of calculating the expected value, we estimate it.   Pick a random sample and calculate it.  Effectively, roll the die.  Monte Carlo search/simulation.  
















	