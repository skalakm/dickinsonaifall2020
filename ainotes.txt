uninformed search 

complete- search that finds a solution (if one exists) 
optimal- finds the best solution 

state- problem state (e.g. "Arad")
node-has a state, a parent, possibly children, possibly cost (e.g. "Arad", "Sibiu", 220)

branching factor- number of child nodes per parent node

depth- distance from root to deepest node 


big O and trees 

given a branching factor of b and a depth m, how many nodes are in the tree? 

depth 0, 1 node 
depth 1, b nodes 
depth 2, b^2 nodes
depth 3, b^3 nodes 
....
depth m, b^m 

Total number of nodes 
1 + b + b^2 + b^3 + ... + b^m = (1-b^(m+1))/(1-b) 
O(b^m)

tree search 
frontier = {root}
while no solution and frontier is not empty
	curNode = frontier.getNode()
	check if it's the solution 
	add children of curNode to frontier 
	

graph search (don't repeat states) 
Collection<Node> frontier = {root}
Collection<State> visited = {root}
while no solution and frontier is not empty
	curNode = frontier.getNode()
	
	check if it's the solution 
	for child in children of curNode 
		
		if child is not in visited 
			frontier.add(child) 
		visited.add(child)
	
What data structure is frontier?
stack- depth first search 
complete? depends if its graph (yes) or tree (no, could get in an infinite loop)
Arad, Sibiu, Arad, Sibiu, Arad, Sibiu, ...
optimal? 
no 
space? 
O(bm) 
speed? 
O(b^m) 

queue- breadth first search 
complete?
yes 
optimal? 
yes 
space? 
O(b^(m-1))
speed?
O(b^m) 

depth limited search- depth first search, but stop if you hit a particular depth d 
complete? 
yes if d>=m, no generally 
optimal? 
no 
space?
O(bd)
speed?
O(b^d) 

iterative deepening 
do a depth limited search.  If it fails, increase depth by 1.
DLS(1), then DLS(2), then DLS(3), ... , DLS(m)
complete? 
yes 
optimal? 
yes 
space?
O(m) 
speed? 
O(b^m)

DLS(0) takes 1
DLS(1) takes b
DLS(2) takes b^2 
DLS(3) takes b^3
....
DLS(m) takes b^m 
1+b+b^2+b^3+...+b^m=O(b^m)


priority queue (ordered by current cost)- uniform cost 
(same issues as bfs) 

	
puzzle 
https://www.chiark.greenend.org.uk/~sgtatham/puzzles/js/fifteen.html


frontier = {initial node}
explored = {}
while frontier isn't empty:
	choose a node N from the frontier, return N if it's a solution
		bfs, queue
		dfs, stack
		uniform cost, priority queue ranked on current distance 
	expand N
		add new nodes to the frontier 
			(don't add nodes already explored)
		depth limited: don't expand if past depth 
	
	
if frontier is empty, return fail


arad to bucharest 

bfs 
arad 

sibiu (arad)
timisoara (arad)
zerind (arad)

fagaras (sibiu)
oradea (sibiu)
rimnicu vilcea (sibiu)
lugoj (timosoara) 

bucharest (fagaras)
pitesti (rimnicu vilcea)
craiova (rimnicu vilcea)
mehadia (lugoj)

expand bucharest (found solution) 
found the shortest path in nodes, not in distance 

dfs 

cur node			stack 
					arad 
arad				zerind, timisoara, sibiu
zerind (arad)		oradea, timisoara, sibiu
oradea	(arad)		timisoara, sibiu
timisoara (arad)	lugoj, sibiu 
lugoj (timi)		mehadia, sibiu 
mehadia	(lugoj)		dobreta, sibiu 
dobreta (mehadia)	craiova, sibiu 
craiova (dobreta)	rimnicu vilcea, pitesti, sibiu
rimnicu vilcea 		pitesti, sibiu
pitesti				bucharest, sibiu 
bucharest			sibiu


we can implement dfs and bfs as special cases of uniform cost 
bfs: cost is number of nodes visited 
dfs: cost is -(number of nodes visited) 


uniform cost 	priority queue
				(arad, 0)
(arad, 0)		(sibiu, 140), (timisoara, 118), (zerind, 75)
(zerind, 75)	(oradea, 71+75=146), (sibiu, 140), (timisoara, 118)
(timisoara, 118) (lugoj, 118+111=229), (oradea, 146), (sibiu, 140)
(sibiu, 140)	(lugoj, 229), (oradea, 146), (rv, 220), (fagaras, 239)
(oradea, 146)	(lugoj, 229), (rv, 220), (fagaras, 239)
(rv, 220)		(lugoj, 229), (pitesti, 317), (craiova, 366),(fagaras, 239)
	
	
current node		priority queue 
					(s, 0)
(s, 0)				(a, 1), (b,2)
(a, 1)				(b,2), (c,4)
(b,2)				(c,3), (c,4)
(c,3)				(c,4), (t,4)
(c,4) ignore		(t,4)
(t,4)
	
Either, you need a way to update nodes in the priority queue, or add a new node with the same state (and deal with extra node when it comes off).	


A* search 
priority queue search 
f - evaluation function
g - cost function 

f = g -> uniform cost 

h - heuristic function (guess at the distance to the goal) 

A*
f = g + h 
	
greedy best first search 
f = h 	

	
	
eights puzzle 
g - total tiles move to this point 

h - number of tiles out of place 
h - how far each tile is from correct spot
	pretend you can move tiles on top of other tiles 
	
	
	
	
	
turing test

thinks a computer needs 10^9 memory/hard drive to imitate a human 

can computer convince a human that it's human? 
text message window, human is allowed to ask questions of the machine (?) and then has to say if it's human or a computer. 


human is talking to A 

"A" might be a human or a computer.  

depends on the tester 

captchas are reverse turing tests.  


1. Theological
Humans are divinely gifted. 

2. Head in the sand
I really hope computers can't do this.

3. Mathematical objection
There are things a computer provably cannot do.

e.g.
Find all bugs in a program.
Tell if a program halts.  

4. Consciousness
Computers can't be conscious.  

5. Disability
Computers aren't able to do X.
Computers are necessarily specialized to a particular task.
Computers don't make mistakes.  

6. Computers can't do anything they are not programmed.

7. Nervous system is continuous, computers are discrete.  

8. Behavior is informal/ not guided by rules.

9. ESP- extra sensory perception 





Games

chess
go/baduk/weiqui ~361!
checkers
tic tac toe
othello
mancala
shogi
xianqi
connect4 
gomoku


two player games
deteriministic (no random elements) 
complete information (no hidden information)
discrete
zero sum (one winner, one loser)



maxPlayer(curState)
	if curState is terminal
		return value
	else
		best = -1000000
		for each childState
			best = max(best, minPlayer(childState) )

		return best

minPlayer(curState)
	if curState is terminal
		return value
	else
		best = 1000000
		for each childState
			best = min(best, maxPlayer(childState) )

		return best
		
findMoveMax(state)
	bestMove = null
	bestVal = -10000
	for each move 
		curVal = minPlayer(childState)
		if(curVal > bestVal)
			bestMove = move
			bestVal = curVal 
	return bestMove 

This solves all games of this type, but the tree is too big for everything but tic tac toe.  

New plan: try to figure out if we are winning without searching the entire tree.  


maxPlayer(curState, depthLeft)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		best = -1000000
		for each childState
			best = max(best, minPlayer(childState, depthLeft-1) )

		return best



What is a static evaluation?
A relatively fast way of assigning a value to a state. 
In chess, a simple one is you count up the pieces each side has.  (A slightly more complex one assigns values to each piece type).  



alpha is what the max player can guarantee
beta is what the min can guarantee 
initially alpha = -infinity, beta = infinity 
maxPlayer(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			
			curValue = minPlayer(childState, depthLeft-1, alpha, beta)
			if(curValue >= beta) // if we can do better than beta, min player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue > alpha // if we can guarantee we do better than previously known, update it 
				alpha = curValue 

		return alpha 


alpha is what the max player can guarantee
beta is what the min can guarantee 
initially alpha = -infinity, beta = infinity 
minPlayer(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			
			curValue = maxPlayer(childState, depthLeft-1, alpha, beta)
			if(curValue <= alpha) // if we can do better than alpha, max player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue < beta // if we can guarantee we do better than previously known, update it 
				beta = curValue 

		return beta 


assuming we are the max player 
negaMax(curState, depthLeft, alpha, beta)
	if curState is terminal
		return value 
	elif depthLeft = 0
		return staticEvaluation(curState)
	else
		for each childState
			curValue = -negaMax(childState, depthLeft-1, -beta, -alpha)
			if(curValue >= beta) // if we can do better than beta, min player will not let us get here
				return curValue  // this value doesnt really matter 
			if curValue > alpha // if we can guarantee we do better than previously known, update it 
				alpha = curValue 
	return alpha 


How much faster is this?
It depends on the order moves are considered.
Minimax is b^d.
If the moves are considered in best to worst order, b^(d/2)
If the moves are considered worst to best, it's b^d. 
If the moves are random, it's b^(3d/4)

If we knew which moves were best, we wouldn't have to do this in the first place.  
One of the places where cleverness comes in is what order to try moves.  Try moves that are usually good first.  It sometimes can be worth it to do a small depth search in order to sort the moves for a large depth search.  






two player games
complete information (no hidden information)
discrete
zero sum (one winner, one loser)

Add in random elements, e.g. card games (without secret hands), dice, dominoes, 



expected value: the average result from a random occurence 

For example, roll one die.

1  1/6
2  1/6
3  1/6 
4  1/6
5  1/6
6  1/6 

Expected value of one die is 1/6 *1 + 1/6 * 2 + 1/6 * 3 + 1/6 * 4 + 1/6 * 5 + 1/6 * 6 = 3.5

Expected value of two dice is 1/36 * 2 + 2/36 * 3 + 3/36 *4 +... + 1/36*12 = 7
11
12
13
14
15
16
21
22
23
24
25
26


What is the expected value of the square of the result of rolling one die?  

1/6 * 1 + 1/6 * 4 + 1/6*9 + 1/6*16 + 1/6 *25 + 1/6*36 = 91/6


2 biased coins.  Chance of heads is .3 on each coin.  You get $3 per heads.  What is the expected payout?

TH  .7*.3  *  3 = .63
HT  .3*.7  *  3 = .63
TT  .7*.7  *  0 = 0
HH  .3*.3  *  6 = .54
.63+.63+.54=1.8 


Solving a stochastic game: (stochastic means nondeterminstic/random)
1. Add chance nodes to our tree (as well as max and min).  
2. At chance nodes, compute the expected value.  



Problems:
1. Often, random events create large branching factors.  
2. If we cut off at a depth, our static evaluation has to not just order states, but give an estimation of winning percentage.  
3. Alpha beta can still work, but it's more complicated.  


a .9 4, .1 5   = 4.1
b .8 2, .2 20  = 5.6
c .8 2, .2 6   = 2.8 


Solution (?):  Instead of calculating the expected value, we estimate it.   Pick a random sample and calculate it.  Effectively, roll the die.  Monte Carlo search/simulation.  




mancala

min max perspective
bottom player is always max 
	pro don't have to adjust static evaluator/some other related things 
	con get move sometimes will ask for the top 
	
get move is always max 
	pro get move is always max, so can be simpler
	con have to adjust static evalutor based on whose turn it is originally 
	
max player changes in recursive calls
	pro can make single minMax function, static evaluator is always in terms of current player 
	con minMax function is a little more complicated  


Double.MIN_VALUE is the smallest nonzero positive value -Double.MAX_VALUE
Integer.MIN_VALUE is the most negative value  
Integer.MIN_VALUE -1 == Integer.MAX_VALUE 
Integer.MIN_VALUE + Integer.MAX_VALUE  = -1



Setup

We have a graph, but with no known properties.  
Each node has a particular value associated with it.
We want to find the node with the highest value.  

n-queens
Arrange n-queens on an nxn board so that no two attack each other (no same row, no same column, no diagonal)

4-queens

qxxx
xxqx
xxxq
xqxx
fail

place queen in each column.  If a queen doesn't work, remove it and try again.  

qxxx
xxxx
xxxx
xxxx

qqxx
xxxx
xxxx
xxxx
fail 

qxxx
xqxx
xxxx
xxxx
fail 

qxxx
xxxx
xqxx
xxxx

qxqx
xxxx
xqxx
xxxx
fail 

qxxx
xxqx
xqxx
xxxx
fail  

This is the recursive backtracking way.  


Nodes- states of board 
Edges- states are connected iff they differ by one queen 
value of board- 1 iff all the queens don't attack each other, 0 otherwise  

Recursive backtracking always works (eventually).  

hill climbing-
Place n queens on the board so that no two are in same column or row. 
Check if swapping any two of them makes the situation better.  Choose the one that improves it the most.  

Nodes- states 
Edges- states are connected if they differ by one swap 
value- number of non attacking queens  

Pro- Takes at most n steps 
problem- It won't always work.  It's possible that no move makes the situation better.  (local maximum) 

solution- restart with a random position 
This will probably find the global maximum (or at least close enough).  


Example

qxxx
xqxx
xxqx
xxxq
6 mutually attacking pairs 

xqxx
qxxx
xxqx
xxxq
2

xxqx
xqxx
qxxx
xxxq
4

xxxq
xqxx
xxqx
qxxx
2

qxxx
xxqx
xqxx
xxxq
2

qxxx
xxxq
xxqx
xqxx
4
ac 
bc
bd 
cd 

qxxx
xqxx
xxxq
xxqx
2

(0,1,3,2)


What if we have continuous search space?  ie state is a vector 

Jump factor/epsilon

Next state generating plan: add/subtract epsilon to one element of the vector 

simulated annealing- Start with epsilon large, decrease it as the algorithm progresses.  

(hemoglobin, height, weight, test result a, ...)


------------------------------------
genetic algorithms 

pro doesnt get stuck in a local maximum, might be better for large input dimensions 
con tends to be more computationally intensive, less predictable, less reproduceable (randomness)



Questions you should be thinking about

Does David pass the Turing Test?

In what ways does he seem not like a normal child (both in actions and in how others treat him)?

In what ways does he seem like a normal child?  


1.00	12.0	12.0	Undefeated and Untied
0.92	11.0	12.0	JessieMaxDeathmatch
0.75	9.0	12.0	HeuristicPlayer
0.75	9.0	12.0	Mancala Cage Match player
0.67	8.0	12.0	alex
0.67	8.0	12.0	Boo
0.50	6.0	12.0	NearRandom
0.42	5.0	12.0	theShaker
0.33	4.0	12.0	MDMancalaPlayer
0.25	3.0	12.0	OneMove
0.17	2.0	12.0	AEDaBest
0.08	1.0	12.0	Random
0.00	0.0	12.0	RRandom


w%	wins	games	name
1.00	5.0	5.0	Undefeated and Untied
0.80	4.0	5.0	alex
0.60	3.0	5.0	Boo
0.40	2.0	5.0	HeuristicPlayer
0.20	1.0	5.0	JessieMaxDeathmatch
0.00	0.0	5.0	Mancala Cage Match player




Let n, the board size, be an even number. Let A's strategy be "always move forwards".  When it is A's turn, the distance between them is always odd before any jumping.  B can move backwards at most half the time because otherwise it would move off the board, so eventually the distance between them becomes 1.  At this point, A jumps B.  Since A has always moved forward and A has moved forward 2 steps by jumping, it must be closer to its endpoint than B is to its endpoint.  Therefore A reaches the endpoint before B does.  


rated rulers on aggressiveness 
0-10, 0 is very peaceful, 10 is very aggressive 

Gandhi was a 1.  When a civ adopted democracy, aggressiveness was reduced by 2.  1-2=255




propositional logic 

This is use a lot.
program correctness- how do you prove a program works? 
testing?/test coverage- cannot prove it works because we cannot test every option 

pacemakers and airplane code 

int x =2;

x = x +4;
if(x > 3)
x++;

prove x = 7



atomic sentences- statements that are true or false  

B="Col Mustard is the murderer" 
A="The murder was with the rope"

A model assigns values (true or false) to each atomic statement. 
A is True, B is False 

A&&B (conjunction)
!A  (negation)
B||!A (disjunction)
A->B (implication)  

A (complex) sentence is a legitimate combination of symbols.  (legitimate means it compiles)
A &&( B || C) -> D 

&& and 
|| or 
!  not 
-> implies 
<-> if and only if, dual implication 


Two sentences are logically equivalent if they are true in exactly the same set of models.  


A sentence is valid (or a tautology) if it is true in all models. 
P || !P 
(P&& (P->Q) )-> Q 

satisfiable if there exists a model where it's true 
P&&Q is satisfiable, but not valid 

unsatisfiable if it is not true in any model 
P && !P 


deMorgan 
!(P&&Q) is equivalent !P || !Q 

implication elimination 
P->Q is equivalent to !P||Q 

iff 
(P<->Q) is equivalent to (P->Q) && (Q->P)

distributivity 
P && ( Q || R) is equivalent to (P&&Q)||(P&&R) 
P || (Q&&R) is equivalent to (P||Q) && (P||R) 

a) (P<->Q) && (P->!Q) (satisfiable) Q is false, P is false 
b) (P||Q) && !Q (satisfiable) Q is false, P is true 
Say if these are satisfiable, valid, or unsatisfiable



clause- the "or" of a set of atomic sentences (with possible negations) 
P||Q
P||!Q 
!P||R||Q 


A sentence is in conjunctive normal form iff it is the "and" of some clauses 
(P||Q)&&(P||!Q)&&(!P||R||Q) 

Any sentence can be converted to CNF (in linear time)
1. Eliminate <-> 
2. Eliminate -> 
3. Move ! inwards. 
4. Distribute || over &&. 


P <-> (Q&& R)

1. (P-> (Q&& R)) && (Q&&R->P) 
2. (!P || (Q&& R)) && ( !(Q&&R) || P)
3. (!P || (Q&&R) ) && ( !Q || !R || P) 
4. (!P||Q) &&( !P ||R) && (!Q||!R||P)


A knowledge base (KB) is a set of statements known to be true.  (Could combine into a single statement with and).  

KB= {P, P->Q, !R, S&&T } 

Inference rules- ways of adding to the knowledge base.

"and elimination"- if A&&B are in the KB, then we can add A to the knowledge base.  
If A&&B are in the KB, then we can add B to the knowledge base.  

KB= {P, P->Q, !R, S&&T, S, T} 

"modus ponens"- If A and A->B are in the KB, then we can add B to the KB.  

KB= {P, P->Q, !R, S&&T, S, T, Q} 

"resolution"

P||Q, R||!Q, then we can add P||R.

P||Q||!R||S, Q||R||T||!U 
We see !R on one side, R on the other side. 
This makes P||Q||S||T||!U.

KB = {P||!Q, !P||R||!S, S||T} 
P||!Q, !P||R||!S makes !Q||R||!S. 

!P||R||!S, S||T makes !P||R||T

KB = {P||!Q, !P||R||!S, S||T, !P||R||T, !Q||R||!S} 
S||T, !Q||R||!S makes T||!Q||R 
P||!Q,!P||R||T makes !Q||R||T 

KB = {P||!Q, !P||R||!S, S||T, !P||R||T, !Q||R||!S, T||!Q||R } 


P->Q is the same as !P || Q 
KB = {P, !P||Q} 
P, !P||Q makes Q 


P||Q, R||!Q, then we can add P||R.

P||Q||!R||S, Q||R||T||!U 
We see !R on one side, R on the other side. 
This makes P||Q||S||T||!U

(1) {¬A,¬B}
(2) {B,A} 
(3) {¬B,¬C} 
(4) {C,B} 
(5) {¬C,¬A} 
(6) {¬C,¬B} 
(7) {A,B,C}
(8) {C}

Generate all possible clauses using resolution.  

(9)  {B,!C}   2, 5
(10) {B,!B}   1, 2
(11) {A,!A}   1, 2 
(12) {A,!B,B} 7, 6
(13) {A,!C,C} 7, 6
(14) {!A,B}   4, 5
(15) {!A,C}   1, 4
(16) {!B}     3, 8
(17) {A,!C}   2, 3
(18) {A,!C}   2,6 
(19) {A}      2, 16
(20) {B}      14, 19
(21) {}       16, 20
Contradiction 


c_p means "card c is in location p"

wrench_player1 

1. Each card is in at least on place. 
for each card c 
	c_player1 || c_player2 || c_player3 || c_casefile

2. If a card is in one placed, it's not in another place. 

for each card c 
	c_player1 -> !(c_player2 || c_player3 || c_casefile)
	!c_player1 || !(c_player2 || c_player3 || c_casefile)
	!c_player1 || (!c_player2 && !c_player3 && !c_casefile)
	(!c_player1 || !c_player2) && (!c_player1 || !c_player3 ) && (!c_player1 || !c_casefile)
	(repeat for other players) 
	
	
First order logic 
(prolog) 

for all cards c, there exists a location where c is.

for all- universal quantifier 
there exists- existential quantifier 

relation- r(x,y)
boolean functions, boolean statements 

father(prof skalak, gregory).

for all x, there exists a y s.t. father(y,x). 


Inference in first order logic 
1. Substitutions

notation subst({x|A}, alpha)
Replace x with A in the sentence alpha.  

subst( {x|John, y|mother(John)}, knows(x,y))
becomes knows(John, mother(John))

subst( {x|z, y|z}, knows(x,y))
becomes knows(z,z).

for all x,y,z, (knows(x,y) and knows(y,z)) implies knows(x,z)
knows(jessie, alex).
knows(alex, iris).

substitute 
({x|jessie, y|alex, z|iris}, for all x,y,z, (knows(x,y) and knows(y,z)) implies knows(x,z))
becomes 
knows(jessie,alex) and knows(alex,iris) implies knows(jessie,iris)


2. propositionalization- converting first order logic into propositional logic 

FOL 
for every student s in the ai class, csmajor(s)

universal instantiation-
replacing a universal with an 'and' clause (or alternatively several clauses)
csmajor(jessie) and csmajor(beverly) and csmajor(anthony) ... and csmajor(lan)
















	